# Image-Captioning-Project

In this project, a neural network architecture to automatically generate captions from images.

After using the Microsoft Common Objects in COntext (MS COCO) dataset to train the network, new captions will be generated based on new images.

## The project Structure


[](Image-Captioning/model.py): containing the model architecture.
[](Image-Captioning/2_Training.ipynb): data pre-processing and training pipeline .
[](Image-Captioning/3_Inference.ipynb): generate captions on test dataset using the trained model.

